{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Autoencoder on fashion mnist\n",
    "> Only differences to `cnn_autoencover_fastai2022.ipynb` is the cell loading the data and the number of epochs to overfit on a single image and the number of epochs for all images. Fashion MNIST seems to need a few more iterations but yields similar results to MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* fastai 2022 / 2023 course part II:\n",
    "    * [notebook 8](https://github.com/fastai/course22p2/blob/master/nbs/08_autoencoder.ipynb)\n",
    "    * [lesson 15](https://course.fast.ai/Lessons/lesson15.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing as T\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import random_neural_net_models.cnn_autoencoder_fastai2022 as cnn_ae\n",
    "import random_neural_net_models.convolution_lecun1990 as conv_lecun1990\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"Fashion-MNIST\", version=1, cache=True, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a few images to overfit on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1\n",
    "X0, y0 = X.iloc[:n], y.iloc[:n]\n",
    "X0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conv_lecun1990.DigitsDataset(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds[0]\n",
    "plt.imshow(item[0], cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {item[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_ae.Model()\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hooks(\n",
    "    model: cnn_ae.Model,\n",
    "    hook_func: T.Callable = partial(\n",
    "        conv_lecun1990.append_stats, hist_range=(0, 4)\n",
    "    ),\n",
    ") -> T.List[conv_lecun1990.Hook]:\n",
    "    model_acts = [\n",
    "        model.enc_act1,\n",
    "        model.enc_act2,\n",
    "        model.dec_act1,\n",
    "    ]\n",
    "    act_names = [\"enc_act1\", \"enc_act2\", \"dec_act1\"]\n",
    "    hooks = [\n",
    "        conv_lecun1990.Hook(layer, hook_func, name=name)\n",
    "        for name, layer in zip(act_names, model_acts)\n",
    "    ]\n",
    "    return hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = conv_lecun1990.LossHistory(every_n=1)\n",
    "parameter_history = conv_lecun1990.ParameterHistory(every_n=10)\n",
    "hooks = get_hooks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20_000\n",
    "_iter = 0\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, _) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb)\n",
    "\n",
    "        loss = loss_func(x_pred, xb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        parameter_history(model, _iter)\n",
    "        loss_history(loss, _iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_loss(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_history(parameter_history, \"enc_conv1\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"enc_conv2\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"dec_deconv1\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"dec_deconv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_activations(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.clear_hooks(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, _ = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.to(device)\n",
    "preds = model(train_features)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.to(\"cpu\").detach().numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_features[0].cpu()\n",
    "img_pred = x_pred[0]\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax = axs[0]\n",
    "ax.imshow(img, cmap=\"gray\")\n",
    "ax.set_title(\"Input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(img_pred, cmap=\"gray\")\n",
    "ax.set_title(\"Reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can also overfit a single fashion mnist image using this setup, although the picture seems slightly blurry. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducing all items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0, X1, y0, y1 = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conv_lecun1990.DigitsDataset(X0, y0)\n",
    "ds_test = conv_lecun1990.DigitsDataset(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(ds_test, batch_size=500, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cnn_ae.Model()\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = conv_lecun1990.LossHistory(every_n=1)\n",
    "loss_history_test = conv_lecun1990.LossHistory(every_n=1)\n",
    "parameter_history = conv_lecun1990.ParameterHistory(every_n=10)\n",
    "hooks = get_hooks(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "_iter = 0\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, _) in tqdm.tqdm(\n",
    "        enumerate(dataloader), desc=\"Batches\", total=len(dataloader)\n",
    "    ):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb)\n",
    "\n",
    "        loss = loss_func(x_pred, xb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        parameter_history(model, _iter)\n",
    "        loss_history(loss, _iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "    # compute validation loss\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        xs_pred, xs_true = [], []\n",
    "        for xb, _ in dataloader_test:\n",
    "            xb = xb.to(device)\n",
    "\n",
    "            x_pred = model(xb)\n",
    "            xs_pred.append(x_pred)\n",
    "            xs_true.append(xb)\n",
    "\n",
    "        x_pred = torch.cat(xs_pred, dim=0)\n",
    "        x_true = torch.cat(xs_true, dim=0)\n",
    "        loss_test = loss_func(x_pred, x_true)\n",
    "        loss_history_test(loss_test, _iter)\n",
    "        model.train()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_loss(loss_history)\n",
    "conv_lecun1990.draw_loss(loss_history_test, label=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_history(parameter_history, \"enc_conv1\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"enc_conv2\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"dec_deconv1\")\n",
    "conv_lecun1990.draw_history(parameter_history, \"dec_deconv2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.draw_activations(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lecun1990.clear_hooks(hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features, _ = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_features.to(device)\n",
    "preds = model(test_features)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.to(\"cpu\").detach().numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pair(img: torch.Tensor, img_pred: torch.Tensor):\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    ax = axs[0]\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(\"Input image\")\n",
    "    ax.axis(\"off\")\n",
    "    ax = axs[1]\n",
    "    ax.imshow(img_pred, cmap=\"gray\")\n",
    "    ax.set_title(\"Reconstructed image\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def draw_n_pairs(\n",
    "    input_features: torch.Tensor, x_pred: torch.Tensor, n: int = 5\n",
    "):\n",
    "    _n = min(n, len(input_features))\n",
    "    print(f\"Drawing {_n} pairs\")\n",
    "    for i in range(_n):\n",
    "        img = input_features[i].cpu()\n",
    "        img_pred = x_pred[i]\n",
    "        draw_pair(img, img_pred)\n",
    "\n",
    "\n",
    "draw_n_pairs(test_features, x_pred, n=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training seems to have phases where the model parameters / loss plateau before improving for fashion mnist as well. Also the reconstructed images are a little bit blurry, but subjectively not as much as in the [fashion mnist example used in the lectures](https://github.com/fastai/course22p2/blob/master/nbs/08_autoencoder.ipynb). So in the lectures nb they probably just did not run the training for long enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
