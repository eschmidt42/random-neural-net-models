{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* _Rumelhart et al. 1986, Learning representations by back-propagating errors_, [nature](https://www.nature.com/articles/323533a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.datasets as sk_datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random_neural_net_models.backprop_rumelhart as backprop_rumelhart\n",
    "import random_neural_net_models.data as rnnm_data\n",
    "import random_neural_net_models.learner as rnnm_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_datasets.make_regression(\n",
    "    n_samples=100, n_features=1, noise=20, random_state=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=y)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sk_datasets.make_blobs(\n",
    "    n_samples=1_000,\n",
    "    n_features=2,\n",
    "    centers=2,\n",
    "    random_state=SEED,\n",
    ")\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, alpha=0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rumelhart et al. 1986, \"Learning representations by back-propagating errors\"\n",
    "> The following is in the spirit of the paper, *cough*. Found the presentation in the paper somewhat hard to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With input $x$ we predict $y$ using a function $f$ like\n",
    "\n",
    "$$\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$ uses weight $w$ and some non-linearity $g$ like\n",
    "\n",
    "$$\n",
    "z =  x \\cdot w^T \\\\\n",
    "f(x) = g(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper they use the sigmoid\n",
    "$$\n",
    "g(z) = \\frac{1}{1+\\exp(-z)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicating repeating weight multiplication and non-linearity with index $i$ (layer), we can write\n",
    "\n",
    "$$\n",
    "\n",
    "z_1 =  x \\cdot w_1 ^ T \\\\\n",
    "a_1 = g_1(z_1) \\\\\n",
    "\n",
    "...\\\\\n",
    "\n",
    "z_{i} = a_{i-1} \\cdot w_{i}^T \\\\\n",
    "a_{i} = g_{i}(z_{i}) \\\\\n",
    "\n",
    "...\\\\\n",
    "\n",
    "z_N = a_{N-1} \\cdot w_N^T \\\\\n",
    "a_N = g_N(z_N) \\\\\n",
    "\n",
    "f(x) = a_N\n",
    "\n",
    "$$\n",
    "\n",
    "where $a_i$ is \"activation\" of layer $i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing predictions to desired valued $d$ we denote deviations / the loss as $l(d,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we can identify how to change $w_i$ by how much lead to the strongest improvement of $l(d,y)$ for any $x$, $y$, $d$ by differentiating $l$. A straightforward way is scaling that gradient and applying it like\n",
    "\n",
    "$$\n",
    "\n",
    "w_{i,\\text{new}} = w_{i,\\text{old}} + \\epsilon \\frac{d}{dw_i}l(d,y)\n",
    "\n",
    "$$\n",
    "\n",
    "with some factor $\\epsilon \\in [0,1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{d}{dw_i}l(d,y)$ can analytically be derived using the chain rule as \n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{d}{dw_i}l(d,y) = l^\\prime(d,y) \\cdot g_N^\\prime(z_N) \\cdot z_N^\\prime \\cdot g_{N-1}^\\prime(z_{N-1}) \\cdot z_{N-1}^\\prime \\cdot \\space ... \\space \\cdot g_{i}^\\prime(z_{i}) \\cdot a_{i-1}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing $z^\\prime = \\frac{\\partial}{\\partial a}z = w ^ T$\n",
    "$$\n",
    "\n",
    "\\frac{d}{dw_i}l(d,y) = l^\\prime(d,y) \\cdot g_N^\\prime(z_N) \\cdot w_N ^ T \\cdot g_{N-1}^\\prime(z_{N-1}) \\cdot w_{N-1} ^ T \\cdot \\space ... \\space \\cdot g_{i}^\\prime(z_{i}) \\cdot a_{i-1}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another version proposed in Rumelhart et al. is\n",
    "$$\n",
    "\n",
    "w_{i,\\text{new}} = w_{i,\\text{old}} + \\epsilon \\frac{d}{dw_i}l(d,y) + \\alpha \\left( \\frac{d}{dw_i}l(d,y) \\right)_\\text{old}\n",
    "\n",
    "$$\n",
    "\n",
    "with some factor $\\alpha \\in [0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(-10, 10, 100)\n",
    "a = backprop_rumelhart.sigmoid(x)\n",
    "a_prime = backprop_rumelhart.sigmoid_derivative(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=x, y=a, label=\"g(z): sigmoid\")\n",
    "sns.lineplot(x=x, y=a_prime, label=\"dg(z)/dz: sigmoid derivative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backprop_rumelhart.Rumelhart1986PerceptronClassifier(\n",
    "    n_hidden=(10, 5), epochs=10, verbose=True, eps=1e-3, alpha=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.errors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T\n",
    "X_plot[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = model.predict_proba(X_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_prob.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and now with `Learner` & pytorch tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = rnnm_data.TabularNumpyDatasetTrain(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(\n",
    "    ds,\n",
    "    batch_size=10,\n",
    "    collate_fn=rnnm_data.tabular_numpy_collate_train,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = backprop_rumelhart.Rumelhart1986PytorchPerceptron(\n",
    "    n_hidden=(2, 10, 5, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_callback = rnnm_learner.LRFinderCallback(1e-5, 100, 100)\n",
    "\n",
    "loss_callback = rnnm_learner.TrainLossCallback()\n",
    "activations_callback = rnnm_learner.TrainActivationsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*act\",)\n",
    ")\n",
    "gradients_callback = rnnm_learner.TrainGradientsCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*lin\",)\n",
    ")\n",
    "parameters_callback = rnnm_learner.TrainParametersCallback(\n",
    "    every_n=10, max_depth_search=4, name_patterns=(\".*lin\",)\n",
    ")\n",
    "callbacks = [\n",
    "    loss_callback,\n",
    "    activations_callback,\n",
    "    gradients_callback,\n",
    "    parameters_callback,\n",
    "]\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=10, momentum=1e-3)\n",
    "loss = backprop_rumelhart.BCELoss()\n",
    "save_dir = Path(\"./models\")\n",
    "learner = rnnm_learner.Learner(\n",
    "    model, optimizer, loss, callbacks=callbacks, save_dir=save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.find_learning_rate(dl, n_epochs=10, lr_find_callback=lr_find_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find_data = lr_find_callback.get_losses()\n",
    "lr_find_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "sns.lineplot(data=lr_find_data, x=\"lr\", y=\"smooth_loss\", ax=ax, label=\"smooth\")\n",
    "sns.lineplot(data=lr_find_data, x=\"lr\", y=\"loss\", ax=ax, label=\"raw\")\n",
    "ax.legend(title=\"loss type\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(dl, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = loss_callback.get_losses()\n",
    "sns.scatterplot(data=losses, x=\"iteration\", y=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = parameters_callback.get_stats()\n",
    "parameters.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 12), nrows=3, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(data=parameters, x=\"iter\", y=\"mean\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[1]\n",
    "sns.scatterplot(data=parameters, x=\"iter\", y=\"std\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[2]\n",
    "sns.scatterplot(data=parameters, x=\"iter\", y=\"abs_perc90\", hue=\"name\", ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = gradients_callback.get_stats()\n",
    "gradients.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 12), nrows=4, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(data=gradients, x=\"call\", y=\"mean\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[1]\n",
    "sns.scatterplot(data=gradients, x=\"call\", y=\"std\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[2]\n",
    "sns.scatterplot(data=gradients, x=\"call\", y=\"frac_dead\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[3]\n",
    "sns.scatterplot(data=gradients, x=\"call\", y=\"abs_perc90\", hue=\"name\", ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = activations_callback.get_stats()\n",
    "activations.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 12), nrows=3, sharex=True)\n",
    "\n",
    "ax = axs[0]\n",
    "sns.scatterplot(data=activations, x=\"call\", y=\"mean\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[1]\n",
    "sns.scatterplot(data=activations, x=\"call\", y=\"std\", hue=\"name\", ax=ax)\n",
    "\n",
    "ax = axs[2]\n",
    "sns.scatterplot(data=activations, x=\"call\", y=\"frac_dead\", hue=\"name\", ax=ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.linspace(X[:, 0].min(), X[:, 0].max(), 100)\n",
    "x1 = np.linspace(X[:, 1].min(), X[:, 1].max(), 100)\n",
    "X0, X1 = np.meshgrid(x0, x1)\n",
    "X_plot = np.array([X0.ravel(), X1.ravel()]).T\n",
    "X_plot[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_plot = rnnm_data.TabularNumpyDatasetEval(X_plot)\n",
    "dl_plot = DataLoader(\n",
    "    ds_plot, batch_size=5, collate_fn=rnnm_data.tabular_numpy_collate_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = learner.predict(dl_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = y_prob.detach().numpy()\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.pcolormesh(X0, X1, y_prob.reshape(X0.shape), alpha=0.2)\n",
    "fig.colorbar(im, ax=ax)\n",
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=y, ax=ax, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
