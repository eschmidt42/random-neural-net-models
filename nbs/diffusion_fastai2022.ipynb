{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion on MNIST\n",
    "\n",
    "Goal: denoising diffusion model without latent space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* fastai 2022 / 2023 course part II:\n",
    "    * [notebook 26](https://github.com/fastai/course22p2/blob/master/nbs/26_diffusion_unet.ipynb)\n",
    "    * [lesson 19](https://course.fast.ai/Lessons/lesson19.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchinfo\n",
    "import tqdm\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import random_neural_net_models.convolution_lecun1990 as conv_lecun1990\n",
    "import random_neural_net_models.telemetry as telemetry\n",
    "import random_neural_net_models.unet as unet\n",
    "import random_neural_net_models.unet_with_noise as unet_with_noise\n",
    "import random_neural_net_models.utils as utils\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_OVERFITTING_ONLY = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_deterministic(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a few images to overfit on (limiting to the number 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n0 = 32\n",
    "n1 = 1_000\n",
    "is_5 = y == \"5\"\n",
    "X0, y0 = X.loc[is_5].iloc[:n0], y.loc[is_5].iloc[:n0]\n",
    "X1, y1 = X.loc[is_5].iloc[n0 : n1 + n0], y.loc[is_5].iloc[n0 : n0 + n1]\n",
    "X0.shape, X1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = conv_lecun1990.DigitsDataset(X0, y0)\n",
    "ds_test = conv_lecun1990.DigitsDataset(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds[0]\n",
    "plt.imshow(item[0], cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {item[1]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying noise based on \n",
    "```python\n",
    "def noisify(x0):\n",
    "    device = x0.device\n",
    "    sig = (torch.randn([len(x0)])*1.2-1.2).exp().to(x0).reshape(-1,1,1,1)\n",
    "    noise = torch.randn_like(x0, device=device)\n",
    "    c_skip,c_out,c_in = scalings(sig)\n",
    "    noised_input = x0 + noise*sig\n",
    "    target = (x0-c_skip*noised_input)/c_out\n",
    "    return (noised_input*c_in,sig.squeeze()),target\n",
    "```\n",
    "from https://github.com/fastai/course22p2/blob/master/nbs/26_diffusion_unet.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_tuples_to_tensors(\n",
    "    batch: T.List[T.Tuple[torch.Tensor, int]]\n",
    ") -> T.Tuple[torch.Tensor, torch.Tensor]:\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images)\n",
    "    labels = torch.tensor(labels, dtype=int)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "SIG_DATA = 0.66\n",
    "\n",
    "\n",
    "def get_cs(\n",
    "    sig: torch.Tensor,\n",
    ") -> T.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # TODO: wtf is happening here?\n",
    "    totvar = sig**2 + SIG_DATA**2\n",
    "    c_skip = SIG_DATA**2 / totvar\n",
    "    c_out = sig * SIG_DATA / totvar.sqrt()\n",
    "    c_in = 1 / totvar.sqrt()\n",
    "    return c_skip, c_out, c_in\n",
    "\n",
    "\n",
    "def draw_sig_from_noise_prior(n: int) -> torch.Tensor:\n",
    "    \"Draws noise level (prior) from a log normal distribution\"\n",
    "    sig = torch.randn(n)\n",
    "    sig = 1.2 * sig - 1.2\n",
    "    sig = sig.exp()\n",
    "    return sig\n",
    "\n",
    "\n",
    "def draw_img_noise_given_sig(\n",
    "    sig: torch.Tensor,\n",
    "    images: torch.Tensor = None,\n",
    "    images_shape: T.Tuple[int, int, int] = None,\n",
    ") -> torch.Tensor:\n",
    "    \"Draws noise from a normal distribution given the noise level (sig)\"\n",
    "    if images is not None:\n",
    "        images_shape = images.shape\n",
    "\n",
    "    noise = torch.randn(images_shape)\n",
    "    noise = noise * sig\n",
    "    return noise\n",
    "\n",
    "\n",
    "def fudge_original_images(images: torch.Tensor) -> torch.Tensor:\n",
    "    return images * 2 - 1\n",
    "\n",
    "\n",
    "def apply_noise(\n",
    "    batch: T.List[T.Tuple[torch.Tensor, int]]\n",
    ") -> T.Tuple[T.Tuple[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
    "    \"Applies noise to the input image and returns the noisy image, the noise level and the de-noised image\"\n",
    "\n",
    "    orig_images, _ = list_of_tuples_to_tensors(batch)\n",
    "\n",
    "    orig_images = fudge_original_images(orig_images)\n",
    "\n",
    "    # drawing noise level (prior) from a log normal distribution\n",
    "    sig = draw_sig_from_noise_prior(orig_images.shape[0])\n",
    "    sig = sig.reshape(-1, 1, 1)\n",
    "\n",
    "    c_skip, c_out, c_in = get_cs(sig)\n",
    "\n",
    "    # adding noise to the image\n",
    "    noise = draw_img_noise_given_sig(sig, images=orig_images)\n",
    "    noisy_images = orig_images + noise\n",
    "\n",
    "    target_noise = (orig_images - c_skip * noisy_images) / c_out\n",
    "    noisy_images = noisy_images * c_in\n",
    "\n",
    "    sig = sig.squeeze()\n",
    "\n",
    "    return (noisy_images, sig), target_noise\n",
    "\n",
    "\n",
    "def get_denoised_images(\n",
    "    noisy_images: torch.Tensor, predicted_noise: torch.Tensor, sig: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"Returns the de-noised images given the noisy images, predicted noise and the noise level (sig)\"\n",
    "    c_skip, c_out, c_in = get_cs(sig)\n",
    "    denoised_images = predicted_noise * c_out + (noisy_images / c_in) * c_skip\n",
    "    return denoised_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining a dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = n0\n",
    "dataloader = DataLoader(\n",
    "    ds, batch_size=batch_size, shuffle=False, collate_fn=apply_noise\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting the noisified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(noisified_input_images, noise_levels), target_noise = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 0\n",
    "noisy_input_image = noisified_input_images[ix_img].cpu()\n",
    "target_noise = target_noise[ix_img].cpu()\n",
    "\n",
    "sig = noise_levels[ix_img].cpu()\n",
    "c_skip, c_out, c_in = get_cs(sig)\n",
    "denoised_image = target_noise * c_out + (noisy_input_image / c_in) * c_skip\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 7))\n",
    "ax = axs[0]\n",
    "ax.imshow(noisy_input_image, cmap=\"gray\")\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(target_noise, cmap=\"gray\")\n",
    "ax.set_title(\"Target noise\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[2]\n",
    "ax.imshow(denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Denoised image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    \"noisy input\",\n",
    "    pd.Series(noisy_input_image.flatten().numpy()).describe(),\n",
    "    \"target noise\",\n",
    "    pd.Series(target_noise.flatten().numpy()).describe(),\n",
    "    \"denoised image\",\n",
    "    pd.Series(denoised_image.flatten().numpy()).describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(-3, 3, 100)\n",
    "fig, axs = plt.subplots(nrows=3, ncols=1, figsize=(10, 7), sharex=True)\n",
    "ax = axs[0]\n",
    "ax.hist(noisy_input_image.flatten(), bins=bins)\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax = axs[1]\n",
    "ax.hist(target_noise.flatten(), bins=bins)\n",
    "ax.set_title(\"Target noise\")\n",
    "ax = axs[2]\n",
    "ax.hist(denoised_image.flatten(), bins=bins)\n",
    "ax.set_title(\"Denoised image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet.UNetModel(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    list_num_features=(\n",
    "        8,\n",
    "        16,\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")\n",
    "model = telemetry.ModelTelemetry(\n",
    "    model,\n",
    "    loss_names=(\"total\",),\n",
    "    activations_name_patterns=(\".*act.*\",),\n",
    "    gradients_name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    "    parameters_name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    "    max_depth_search=10,\n",
    ")\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input_size=(1, 28, 28), dtypes=[torch.double])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, ((xb, _), yb) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb)\n",
    "\n",
    "        loss = loss_func(x_pred, yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_loss_history_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_images, noise_levels), target_noises = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.to(device)\n",
    "preds = model(input_images)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.detach().cpu()  # .numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 0\n",
    "noisy_input_image = input_images[ix_img].cpu()  # .numpy()\n",
    "pred_noise = x_pred[ix_img]\n",
    "target_noise = target_noises[ix_img].cpu()  # .numpy()\n",
    "sig = noise_levels[ix_img].cpu()\n",
    "\n",
    "c_skip, c_out, c_in = get_cs(sig)\n",
    "denoised_image = target_noise * c_out + (noisy_input_image / c_in) * c_skip\n",
    "pred_denoised_image = pred_noise * c_out + (noisy_input_image / c_in) * c_skip\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 7))\n",
    "ax = axs[0]\n",
    "ax.imshow(noisy_input_image, cmap=\"gray\")\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Ideal reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[2]\n",
    "ax.imshow(pred_denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Model reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_gradient_stats(yscale=\"log\", figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_activation_stats(yscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drawing histograms of the weights and biases across training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_parameter_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clean_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_OVERFITTING_ONLY:\n",
    "    raise SystemExit(\"Skipping training beyond overfitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## including the noise level as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.linspace(-10, 10, 100)\n",
    "emb = unet_with_noise.get_noise_level_embedding(noise, 8 * 4, max_period=1000)\n",
    "print(emb.T.shape)\n",
    "plt.imshow(emb.T)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_with_noise.UNetModel(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    list_num_features=(\n",
    "        8,\n",
    "        16,\n",
    "    ),\n",
    "    num_layers=2,\n",
    ")\n",
    "model = telemetry.ModelTelemetry(\n",
    "    model,\n",
    "    loss_names=(\"total\",),\n",
    "    activations_name_patterns=(\".*act.*\",),\n",
    "    gradients_name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    "    parameters_name_patterns=(r\".*conv\\d\", r\".*convs\\.[25]$\", r\".*idconv$\"),\n",
    "    max_depth_search=10,\n",
    ")\n",
    "model.double()\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=0.1,\n",
    "# )\n",
    "opt = Adam(model.parameters(), lr=4e-3, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_iter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "# opt = SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=0.1,\n",
    "# )\n",
    "opt = Adam(model.parameters(), lr=1e-2, eps=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, ((xb, noise_levels), yb) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb, noise_levels)\n",
    "\n",
    "        loss = loss_func(x_pred, yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "# opt = SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=0.1,\n",
    "# )\n",
    "opt = Adam(model.parameters(), lr=4e-3, eps=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, ((xb, noise_levels), yb) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb, noise_levels)\n",
    "\n",
    "        loss = loss_func(x_pred, yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "# opt = SGD(\n",
    "#     model.parameters(),\n",
    "#     lr=0.1,\n",
    "# )\n",
    "opt = Adam(model.parameters(), lr=4e-4, eps=1e-5)\n",
    "\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, ((xb, noise_levels), yb) in enumerate(dataloader):\n",
    "        xb = xb.to(device)\n",
    "        x_pred = model(xb, noise_levels)\n",
    "\n",
    "        loss = loss_func(x_pred, yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.loss_history_train(loss, _iter)\n",
    "        model.parameter_history(_iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plotting losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.draw_loss_history_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(input_images, noise_levels), target_noises = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inspecting predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = input_images.to(device)\n",
    "noise_levels = noise_levels.to(device)\n",
    "preds = model(input_images, noise_levels)\n",
    "preds[0, :5, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pred = preds.detach().cpu()  # .numpy()\n",
    "x_pred[0, :3, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 2\n",
    "noisy_input_image = input_images[ix_img].cpu()  # .numpy()\n",
    "pred_noise = x_pred[ix_img]\n",
    "target_noise = target_noises[ix_img].cpu()  # .numpy()\n",
    "sig = noise_levels[ix_img].cpu()\n",
    "\n",
    "c_skip, c_out, c_in = get_cs(sig)\n",
    "denoised_image = target_noise * c_out + (noisy_input_image / c_in) * c_skip\n",
    "pred_denoised_image = pred_noise * c_out + (noisy_input_image / c_in) * c_skip\n",
    "\n",
    "print(f\"noise level: {noise_levels[ix_img]}\")\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 7))\n",
    "ax = axs[0]\n",
    "ax.imshow(noisy_input_image, cmap=\"gray\")\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Ideal reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[2]\n",
    "ax.imshow(pred_denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Model reconstructed image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noise levels based on\n",
    "```python\n",
    "def sigmas_karras(n, sigma_min=0.01, sigma_max=80., rho=7.):\n",
    "    ramp = torch.linspace(0, 1, n)\n",
    "    min_inv_rho = sigma_min**(1/rho)\n",
    "    max_inv_rho = sigma_max**(1/rho)\n",
    "    sigmas = (max_inv_rho + ramp * (min_inv_rho-max_inv_rho))**rho\n",
    "    return torch.cat([sigmas, tensor([0.])]).cuda()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmas_karras(\n",
    "    n: int, sigma_min: float = 0.01, sigma_max: float = 80.0, rho: float = 7.0\n",
    ") -> torch.Tensor:\n",
    "    ramp = torch.linspace(0, 1, n)\n",
    "    min_inv_rho = sigma_min ** (1 / rho)\n",
    "    max_inv_rho = sigma_max ** (1 / rho)\n",
    "    sigmas = (max_inv_rho + ramp * (min_inv_rho - max_inv_rho)) ** rho\n",
    "\n",
    "    return torch.cat([sigmas, torch.tensor([0.0])])\n",
    "\n",
    "\n",
    "sigma_max = 0.5\n",
    "sigs = sigmas_karras(100, sigma_max=sigma_max)\n",
    "sigs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=range(len(sigs)), y=sigs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_sig = torch.tensor([sigma_max, sigma_max, sigma_max])\n",
    "sampled_noise = draw_img_noise_given_sig(\n",
    "    generative_sig.reshape(-1, 1, 1),\n",
    "    images_shape=(generative_sig.shape[0], 28, 28),\n",
    ")\n",
    "sampled_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "denoising based on \n",
    "```python\n",
    "def denoise(model, x, sig):\n",
    "    sig = sig[None]\n",
    "    c_skip,c_out,c_in = scalings(sig)\n",
    "    return model((x*c_in, sig))*c_out + x*c_skip\n",
    "    \n",
    "def sample_lms(model, steps=100, order=4, sigma_max=80.):\n",
    "    preds = []\n",
    "    x = torch.randn(sz).cuda()*sigma_max\n",
    "    sigs = sigmas_karras(steps, sigma_max=sigma_max)\n",
    "    ds = []\n",
    "    for i in progress_bar(range(len(sigs)-1)):\n",
    "        sig = sigs[i]\n",
    "        denoised = denoise(model, x, sig)\n",
    "        d = (x-denoised)/sig\n",
    "        ds.append(d)\n",
    "        if len(ds) > order: ds.pop(0)\n",
    "        cur_order = min(i+1, order)\n",
    "        coeffs = [linear_multistep_coeff(cur_order, sigs, i, j) for j in range(cur_order)]\n",
    "        x = x + sum(coeff*d for coeff, d in zip(coeffs, reversed(ds)))\n",
    "        preds.append(x)\n",
    "    return preds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise_with_model(\n",
    "    model: telemetry.ModelTelemetry, images: torch.Tensor, sigs: torch.Tensor\n",
    ") -> T.Tuple[T.List[torch.Tensor], T.List[torch.Tensor]]:\n",
    "    \"Denoises an image with the model for a range of noise levels\"\n",
    "    noise_preds = []\n",
    "    denoised_preds = []\n",
    "    for i, sig in tqdm.tqdm(enumerate(sigs), total=len(sigs), desc=\"Sigmas\"):\n",
    "        _sigs = sig.repeat(images.shape[0])\n",
    "\n",
    "        _, _, c_in = get_cs(_sigs.reshape(-1, 1, 1))\n",
    "        if i == 0:\n",
    "            images = images * c_in\n",
    "\n",
    "        pred_noise = model(images, _sigs)\n",
    "\n",
    "        images = get_denoised_images(\n",
    "            images, pred_noise, _sigs.reshape(-1, 1, 1)\n",
    "        )\n",
    "\n",
    "        noise_preds.append(pred_noise.detach().cpu())\n",
    "        denoised_preds.append(images.detach().cpu())\n",
    "    return noise_preds, denoised_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_preds, denoised_preds = denoise_with_model(\n",
    "    model, sampled_noise.double(), sigs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_img = 0\n",
    "ix_denoise = 5\n",
    "noisy_input_image = sampled_noise[ix_img].cpu()\n",
    "predicted_noise = noise_preds[ix_denoise][ix_img].cpu()\n",
    "denoised_image = denoised_preds[ix_denoise][ix_img].cpu()\n",
    "\n",
    "sig = sigs[ix_denoise].cpu()\n",
    "c_skip, c_out, c_in = get_cs(sig)\n",
    "\n",
    "print(f\"noise level for denoising: {sig}\")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(10, 7))\n",
    "ax = axs[0]\n",
    "ax.imshow(noisy_input_image, cmap=\"gray\")\n",
    "ax.set_title(\"Noisy input image\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[1]\n",
    "ax.imshow(predicted_noise, cmap=\"gray\")\n",
    "ax.set_title(\"Predicted noise\")\n",
    "ax.axis(\"off\")\n",
    "ax = axs[2]\n",
    "ax.imshow(denoised_image, cmap=\"gray\")\n",
    "ax.set_title(\"Denoised image\")\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: above sampling does not quite lead to the generation of the number 5, unclear when how many of the sigmas should be used since sometimes the first few already give much better results than the last"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
