{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Convolution based neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* LeCun et al. 1990, _Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning_, [Neurocomputing](https://link.springer.com/chapter/10.1007/978-3-642-76153-9_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first item in dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "# load mnist using scikit-learn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeCun et al. 1990, \"Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning\"\n",
    "> The following tries to reproduce the original paper. Note that the digits dataset actually used in the paper could not be found and [MNIST 784](https://www.openml.org/search?type=data&status=active&id=554) is used instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifics in the paper:\n",
    "\n",
    "* neural net\n",
    "    * weight initialization: uniformly at random $\\in [-2.4 / F_i, 2.4 / F_i]$ with $F_i = $ number of inputs of the unit\n",
    "    * \"tanh activation\": $A \\cdot \\tanh (S \\cdot a)$ with $A = 1.716$, $S = 2/3$ and $a = \\text{weights} \\cdot \\text{input}$\n",
    "    * 256 input (16 x 16 pixel images)\n",
    "    * layer #1: \n",
    "        * convolution with 12 5x5-kernels and stride 2 (output: 8 x 8 x 12 = 786 \"units\")\n",
    "        * tanh activation\n",
    "        * $F_i = 25$?\n",
    "    * layer #2: \n",
    "        * convolution with 12 5x5-kernels and stride 2 (output: 4 x 4 x 12 = 192 \"units\")\n",
    "        * tanh activation\n",
    "        * $F_i = 25$?\n",
    "    * layer #3:\n",
    "        * dense with 30 neurons\n",
    "        * tanh activation\n",
    "        * $F_i = 192$\n",
    "    * layer #4:\n",
    "        * dense output layer with 10 neurons\n",
    "        * tanh activation\n",
    "        * $F_i = 30$\n",
    "* target: vector of 10 values either 1 or -1 (so 9x -1 and 1x 1)\n",
    "* loss: mean squared error between prediction and target (paper reached 1.8e-2 on test and 2.5e-3 on train)\n",
    "* error rates: 0.14% on train, 5% on test\n",
    "* training:\n",
    "    * stochastic gradient descent (1 sample per backpropagation)\n",
    "    * samples always in the same order, no shuffeling\n",
    "    * 23 or 30 epochs, paper is ambiguous\n",
    "    * learning rate was set using some not defined 2nd order derivative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix0 = 100\n",
    "X0, y0 = X[:ix0], y[:ix0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = (\n",
    "            torch.from_numpy(self.X.iloc[idx].values / 255.0)\n",
    "            .reshape(28, 28)\n",
    "            .double()\n",
    "        )\n",
    "        label = int(self.y.iloc[idx])\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DigitsDataset(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds[4]\n",
    "plt.imshow(item[0], cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {item[1]}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0]  # .reshape((28,28))\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_conv_output_dim(input_dim, kernel_size, padding, stride):\n",
    "    return int((input_dim - kernel_size + 2 * padding) / stride + 1)\n",
    "\n",
    "\n",
    "calc_conv_output_dim(28, 5, 2, 2), calc_conv_output_dim(14, 5, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, edge: int = 28, n_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 12, kernel_size=5, stride=2, padding=2)\n",
    "        edge = edge // 2  # effect of stride\n",
    "        self.conv2 = nn.Conv2d(12, 12, kernel_size=5, stride=2, padding=2)\n",
    "        edge = edge // 2  # effect of stride\n",
    "        self.lin1 = nn.Linear(edge * edge * 12, 30)\n",
    "        self.lin2 = nn.Linear(30, n_classes)\n",
    "        self.act = F.tanh\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.act(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, yb) in tqdm.tqdm(\n",
    "        enumerate(dataloader), desc=\"Batches\", total=len(dataloader)\n",
    "    ):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.to(device)\n",
    "pred_probs = model(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred_probs.to(\"cpu\").detach().numpy().argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].cpu()  # .reshape((28,28))\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}, pred: {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
