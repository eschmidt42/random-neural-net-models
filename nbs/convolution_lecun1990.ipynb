{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Convolution based neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* LeCun et al. 1990, _Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning_, [Neurocomputing](https://link.springer.com/chapter/10.1007/978-3-642-76153-9_35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing as T\n",
    "from collections import defaultdict\n",
    "\n",
    "# plot first item in dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "\n",
    "# load mnist using scikit-learn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeCun et al. 1990, \"Handwritten Digit Recognition: Applications of Neural Net Chips and Automatic Learning\"\n",
    "> The following tries to reproduce the original paper. Note that the digits dataset actually used in the paper could not be found and [MNIST 784](https://www.openml.org/search?type=data&status=active&id=554) is used instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "specifics in the paper:\n",
    "\n",
    "* neural net\n",
    "    * weight initialization: uniformly at random $\\in [-2.4 / F_i, 2.4 / F_i]$ with $F_i = $ number of inputs of the unit\n",
    "    * \"tanh activation\": $A \\cdot \\tanh (S \\cdot a)$ with $A = 1.716$, $S = 2/3$ and $a = \\text{weights} \\cdot \\text{input}$\n",
    "    * 256 input (16 x 16 pixel images)\n",
    "    * layer #1: \n",
    "        * convolution with 12 5x5-kernels and stride 2 (output: 8 x 8 x 12 = 786 \"units\")\n",
    "        * tanh activation\n",
    "        * $F_i = 5 \\cdot 5 \\cdot n_\\text{input-channels} = 5 \\cdot 5 \\cdot 1 = 25$\n",
    "    * layer #2: \n",
    "        * convolution with 12 5x5-kernels and stride 2 (output: 4 x 4 x 12 = 192 \"units\")\n",
    "        * tanh activation\n",
    "        * $F_i = 5 \\cdot 5 \\cdot n_\\text{input-channels} = 5 \\cdot 5 \\cdot 12 = 300$\n",
    "    * layer #3:\n",
    "        * dense with 30 neurons\n",
    "        * tanh activation\n",
    "        * $F_i = 4 \\cdot 4 \\cdot 12 = 192$\n",
    "    * layer #4:\n",
    "        * dense output layer with 10 neurons\n",
    "        * tanh activation\n",
    "        * $F_i = 30$\n",
    "* target: vector of 10 values either 1 or -1 (so 9x -1 and 1x 1)\n",
    "* loss: mean squared error between prediction and target (paper reached 1.8e-2 on test and 2.5e-3 on train)\n",
    "* error rates: 0.14% on train, 5% on test\n",
    "* training:\n",
    "    * stochastic gradient descent (1 sample per backpropagation)\n",
    "    * samples always in the same order, no shuffling\n",
    "    * 23 or 30 epochs, paper is ambiguous\n",
    "    * learning rate was set using some not defined 2nd order derivative method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\", version=1, cache=True, parser=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device() -> str:\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix0 = 100\n",
    "X0, y0 = X[:ix0], y[:ix0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, X: pd.DataFrame, y: pd.Series, edge: int = 28):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.edge = edge\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> T.Tuple[torch.Tensor, int]:\n",
    "        img = (\n",
    "            torch.from_numpy(self.X.iloc[idx].values / 255.0)  # normalizing\n",
    "            .reshape(self.edge, self.edge)\n",
    "            .double()\n",
    "        )\n",
    "        label = int(self.y.iloc[idx])\n",
    "        return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DigitsDataset(X0, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = ds[4]\n",
    "plt.imshow(item[0], cmap=\"gray\", origin=\"upper\")\n",
    "plt.title(f\"Label: {item[1]}\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "dataloader = DataLoader(ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0]  # .reshape((28,28))\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_conv_output_dim(input_dim, kernel_size, padding, stride):\n",
    "    return int((input_dim - kernel_size + 2 * padding) / stride + 1)\n",
    "\n",
    "\n",
    "calc_conv_output_dim(28, 5, 2, 2), calc_conv_output_dim(14, 5, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyConv2d(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge: int,\n",
    "        n_in_channels: int = 1,\n",
    "        n_out_channels: int = 1,\n",
    "        kernel_width: int = 5,\n",
    "        kernel_height: int = 5,\n",
    "        stride: int = 1,\n",
    "        padding: int = 0,\n",
    "        dilation: int = 1,\n",
    "        lecun_init: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(\n",
    "            torch.empty(\n",
    "                n_out_channels,\n",
    "                n_in_channels,\n",
    "                kernel_width,\n",
    "                kernel_height,\n",
    "                dtype=torch.double,\n",
    "            )\n",
    "        )\n",
    "        self.bias = nn.Parameter(\n",
    "            torch.empty(n_out_channels, dtype=torch.double)\n",
    "        )\n",
    "        if lecun_init:\n",
    "            s = 2.4 / (n_in_channels * kernel_width * kernel_height)\n",
    "            self.weight.data.uniform_(-s, s)\n",
    "            self.bias.data.uniform_(-s, s)\n",
    "\n",
    "        else:\n",
    "            self.weight.data.normal_(0, 1.0)\n",
    "            self.bias.data.normal_(0, 1.0)\n",
    "\n",
    "        self.unfold = torch.nn.Unfold(\n",
    "            kernel_size=(kernel_height, kernel_width),\n",
    "            dilation=dilation,\n",
    "            padding=padding,\n",
    "            stride=stride,\n",
    "        )\n",
    "        out_h = out_w = calc_conv_output_dim(\n",
    "            edge, kernel_width, padding, stride\n",
    "        )\n",
    "        self.fold = torch.nn.Fold(\n",
    "            output_size=(out_h, out_w),\n",
    "            kernel_size=(1, 1),\n",
    "            dilation=dilation,\n",
    "            padding=0,\n",
    "            stride=1,\n",
    "        )\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        # inspiration from: https://discuss.pytorch.org/t/make-custom-conv2d-layer-efficient-wrt-speed-and-memory/70175/2\n",
    "        batch_size, in_channels, in_h, in_w = input.shape\n",
    "        out_channels, in_channels_weight, _, _ = self.weight.shape\n",
    "\n",
    "        if in_h != in_w:\n",
    "            raise ValueError(\n",
    "                f\"Input height {in_h} is not equal to width {in_w}\"\n",
    "            )\n",
    "        if in_channels != in_channels_weight:\n",
    "            raise ValueError(\n",
    "                f\"Input channels {in_channels} is not equal to weight input channels {in_channels_weight}\"\n",
    "            )\n",
    "\n",
    "        # (N,C,in_h,in_w) -> (N, C*kh*kw, num_patches)\n",
    "        # N = batch_size, C = in_channels, kh = kernel_height, kw = kernel_width\n",
    "\n",
    "        input_unfolded = self.unfold(input)\n",
    "\n",
    "        # (N, C*kh*kw, num_patches) -> (N, out_channels, num_patches)\n",
    "        input_unfolded = input_unfolded.transpose(\n",
    "            1, 2\n",
    "        )  # (N, num_patches, C*kh*kw)\n",
    "        weight = self.weight.view(\n",
    "            self.weight.size(0), -1\n",
    "        ).T  # (C*kh*kw, out_channels)\n",
    "        output_unfolded = input_unfolded.matmul(weight).transpose(\n",
    "            1, 2\n",
    "        )  # (N, out_channels, num_patches)\n",
    "\n",
    "        output = self.fold(output_unfolded)  # (N, out_channels, out_h, out_w)\n",
    "        if self.bias is not None:\n",
    "            output += self.bias.view(1, -1, 1, 1)\n",
    "\n",
    "        if output.shape[0] != batch_size:\n",
    "            raise ValueError(\n",
    "                f\"Batch size {batch_size} is not equal to output batch size {output.shape[0]}\"\n",
    "            )\n",
    "        if output.shape[1] != out_channels:\n",
    "            raise ValueError(\n",
    "                f\"Output channels {out_channels} is not equal to output channels {output.shape[1]}\"\n",
    "            )\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "kh = kw = 5\n",
    "n_in_channels = 1\n",
    "n_out_channels = 1\n",
    "weight = torch.randn(n_out_channels, n_in_channels, kw, kw).double()\n",
    "bias = torch.randn(n_out_channels).double()\n",
    "print(f\"{weight.shape=}\")\n",
    "train_features, train_labels = next(iter(dataloader))\n",
    "train_features = train_features.unsqueeze(dim=1)\n",
    "print(f\"{train_features.shape=}\")\n",
    "myconv2d = MyConv2d(\n",
    "    edge=28,\n",
    "    n_in_channels=n_in_channels,\n",
    "    n_out_channels=n_out_channels,\n",
    "    kernel_width=kw,\n",
    "    kernel_height=kh,\n",
    "    stride=2,\n",
    "    padding=2,\n",
    "    dilation=1,\n",
    ")\n",
    "conv_features = myconv2d(train_features)\n",
    "print(f\"{conv_features.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_labels[0]\n",
    "fig, axs = plt.subplots(nrows=2, ncols=1, figsize=(5, 5))\n",
    "ax = axs[0]\n",
    "img = train_features[0][0]\n",
    "ax.imshow(img, cmap=\"gray\")\n",
    "ax = axs[1]\n",
    "img = conv_features.detach().numpy()[0][0]\n",
    "ax.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterHistory:\n",
    "    def __init__(self, every_n: int = 1):\n",
    "        self.history = defaultdict(list)\n",
    "        self.every_n = every_n\n",
    "        self.iter = []\n",
    "\n",
    "    def __call__(self, model: nn.Module, _iter: int):\n",
    "        if _iter % self.every_n != 0:\n",
    "            return\n",
    "        state_dict = model.state_dict()\n",
    "\n",
    "        for name, tensor in state_dict.items():\n",
    "            self.history[name].append(tensor.clone().numpy().ravel())\n",
    "\n",
    "        self.iter.append(_iter)\n",
    "\n",
    "\n",
    "class LossHistory:\n",
    "    def __init__(self, every_n: int = 1):\n",
    "        self.history = []\n",
    "        self.iter = []\n",
    "        self.every_n = every_n\n",
    "\n",
    "    def __call__(self, loss: torch.Tensor, _iter: int):\n",
    "        if _iter % self.every_n != 0:\n",
    "            return\n",
    "        self.history.append(loss.item())\n",
    "        self.iter.append(_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhLeCun1990(nn.Module):\n",
    "    def __init__(self, A: float = 1.716, S: float = 2 / 3):\n",
    "        super().__init__()\n",
    "        self.A = A\n",
    "        self.S = S\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.A * torch.tanh(self.S * x)\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        edge: int = 28,\n",
    "        n_classes: int = 10,\n",
    "        lecun_init: bool = True,\n",
    "        lecun_act: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(1, 12, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv1 = MyConv2d(\n",
    "            edge=edge,\n",
    "            n_in_channels=1,\n",
    "            n_out_channels=12,\n",
    "            kernel_width=5,\n",
    "            kernel_height=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            lecun_init=lecun_init,\n",
    "        )\n",
    "        edge = edge // 2  # effect of stride\n",
    "        # self.conv2 = nn.Conv2d(12, 12, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = MyConv2d(\n",
    "            edge=edge,\n",
    "            n_in_channels=12,\n",
    "            n_out_channels=12,\n",
    "            kernel_width=5,\n",
    "            kernel_height=5,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            lecun_init=lecun_init,\n",
    "        )\n",
    "        edge = edge // 2  # effect of stride\n",
    "        self.lin1 = nn.Linear(edge * edge * 12, 30)\n",
    "        self.lin2 = nn.Linear(30, n_classes)\n",
    "\n",
    "        if lecun_init:\n",
    "            s = 2.4 / self.lin1.weight.shape[0]\n",
    "            self.lin1.weight.data.uniform_(-s, s)\n",
    "\n",
    "            s = 2.4 / self.lin2.weight.shape[0]\n",
    "            self.lin2.weight.data.uniform_(-s, s)\n",
    "\n",
    "        if lecun_act:\n",
    "            self.act = TanhLeCun1990()\n",
    "        else:\n",
    "            self.act = F.tanh\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.unsqueeze(dim=1)\n",
    "        x = self.act(self.conv1(x))\n",
    "        x = self.act(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.act(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return self.act(x)\n",
    "        # return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(lecun_init=True, lecun_act=True)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(\n",
    "    model.parameters(),\n",
    "    lr=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_history = ParameterHistory(every_n=10)\n",
    "loss_history = LossHistory(every_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densify_y(y: torch.Tensor) -> torch.Tensor:\n",
    "    new_y = F.one_hot(y, num_classes=10)\n",
    "    new_y[new_y == 0] = -1\n",
    "    return new_y.double()\n",
    "\n",
    "\n",
    "train_labels[0:3], densify_y(train_labels[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "_iter = 0\n",
    "model.train()\n",
    "for epoch in tqdm.tqdm(range(n_epochs), desc=\"Epochs\", total=n_epochs):\n",
    "    for i, (xb, yb) in tqdm.tqdm(\n",
    "        enumerate(dataloader), desc=\"Batches\", total=len(dataloader)\n",
    "    ):\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        yb = densify_y(yb)\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        parameter_history(model, _iter)\n",
    "        loss_history(loss, _iter)\n",
    "\n",
    "        _iter += 1\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "df = pd.DataFrame({\"iter\": loss_history.iter, \"loss\": loss_history.history})\n",
    "df_roll = df.rolling(window=10, on=\"iter\", min_periods=1).mean()\n",
    "\n",
    "sns.lineplot(data=df, x=\"iter\", y=\"loss\", ax=ax, label=\"Train\")\n",
    "sns.lineplot(\n",
    "    data=df_roll, x=\"iter\", y=\"loss\", ax=ax, label=\"Train (rolling mean)\"\n",
    ")\n",
    "ax.set(xlabel=\"Iter\", ylabel=\"Loss\", title=\"Loss History\")\n",
    "plt.tight_layout()\n",
    "\n",
    "display(df_roll.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist2dfy(history: ParameterHistory, name: str) -> pd.DataFrame:\n",
    "    df = [\n",
    "        pd.DataFrame({\"value\": w}).assign(iter=i)\n",
    "        for i, w in zip(history.iter, history.history[name])\n",
    "    ]\n",
    "    return pd.concat(df, ignore_index=True)[[\"iter\", \"value\"]]\n",
    "\n",
    "\n",
    "def draw_history(\n",
    "    history: ParameterHistory,\n",
    "    name: str,\n",
    "    figsize: T.Tuple[int, int] = (12, 4),\n",
    "    weight_bins: int = 20,\n",
    "    bias_bins: int = 10,\n",
    ") -> None:\n",
    "    fig, axs = plt.subplots(figsize=figsize, nrows=2, sharex=True)\n",
    "\n",
    "    ax = axs[0]\n",
    "    _name = f\"{name}.weight\"\n",
    "    df = hist2dfy(history, _name)\n",
    "    n_iter = df[\"iter\"].nunique()\n",
    "    bins = (n_iter, weight_bins)\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=\"iter\",\n",
    "        y=\"value\",\n",
    "        ax=ax,\n",
    "        thresh=None,\n",
    "        cmap=\"plasma\",\n",
    "        bins=bins,\n",
    "    )\n",
    "    ax.set_ylabel(\"weight\")\n",
    "    ax.set_title(name)\n",
    "\n",
    "    ax = axs[1]\n",
    "    _name = f\"{name}.bias\"\n",
    "    df = hist2dfy(history, _name)\n",
    "    bins = (n_iter, bias_bins)\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=\"iter\",\n",
    "        y=\"value\",\n",
    "        ax=ax,\n",
    "        thresh=None,\n",
    "        cmap=\"plasma\",\n",
    "        bins=bins,\n",
    "    )\n",
    "    ax.set_xlabel(\"iter\")\n",
    "    ax.set_ylabel(\"bias\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_history(parameter_history, \"conv1\")\n",
    "draw_history(parameter_history, \"conv2\")\n",
    "draw_history(parameter_history, \"lin1\", weight_bins=100)\n",
    "draw_history(parameter_history, \"lin2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.to(device)\n",
    "pred_probs = model(train_features)\n",
    "pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pred_probs.to(\"cpu\").detach().numpy().argmax(axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].cpu()  # .reshape((28,28))\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}, pred: {y_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = model.conv1.weight.shape[0]\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=n_filters // 3, ncols=n_filters // 4, figsize=(12, 12)\n",
    ")\n",
    "with torch.no_grad():\n",
    "    conv_features = model.act(model.conv1(train_features.unsqueeze(1)))\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        ax.imshow(conv_features[0][i], cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "        ax.set_title(f\"Filter {i+1}\")\n",
    "\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
